# -*- coding: utf-8 -*-
"""Q3_vae.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19oK-0G8GkhvbAK7uY03RDjXio4u52ZPW
"""
import torch
import torch.nn as nn

workers = 4

batch_size = 64

image_size = 32

channels = 3
z_dim = 100

num_epochs = 50

lr = 0.0002

beta1 = 0.5

class Decoder(nn.Module):

    def __init__(self, f=32):
        super(Decoder, self).__init__()

        # base depth nb of feature maps
        self.f = f

        def dc_block(in_size, out_size, k=4, s=2, p=1):
            return nn.Sequential(
                nn.ConvTranspose2d(in_size, out_size, k, s, p, bias=False),
                nn.BatchNorm2d(out_size),
                nn.ReLU(True))

        self.main = nn.Sequential(
            dc_block(100, self.f * 8, 2, 1, 0),
            dc_block(self.f * 8, self.f * 4),
            dc_block(self.f * 4, self.f * 2),
            dc_block(self.f * 2, self.f),
            nn.ConvTranspose2d(self.f, 3, 4, 2, 1, bias=False),
            nn.Tanh()
        )

    def forward(self, x):
        return self.main(x)

def dcgan_init(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        nn.init.normal_(m.weight.data, 0.0, 0.02)
    elif classname.find('Norm') != -1:
        nn.init.normal_(m.weight.data, 1.0, 0.02)
        nn.init.constant_(m.bias.data, 0)

class Encoder(nn.Module):

    def __init__(self, f=32):
        super(Encoder, self).__init__()

        # base depth nb of feature maps
        self.f = f

        def dc_block(in_size, out_size, k=4, s=2, p=1):
            return nn.Sequential(
                nn.Conv2d(in_size, out_size, k, s, p, bias=False),
                nn.BatchNorm2d(out_size),
                nn.LeakyReLU(0.2, inplace=True))

        self.main = nn.Sequential(
            nn.Conv2d(3, self.f, 4, 2, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            dc_block(self.f, self.f * 2),
            dc_block(self.f * 2, self.f * 4),
            dc_block(self.f * 4, self.f * 8),
        )

        self.x_size = self.f * 8 * 2 * 2
        self.mean =  nn.Linear(self.x_size, 100)
        self.logvar =  nn.Linear(self.x_size, 100)
        
        self.relu = nn.ReLU(True)

    def forward(self, x):
        x = self.main(x)
        x = x.view([-1, self.x_size])
        mean = self.mean(x)
        logvar = self.logvar(x)
        
        return mean, logvar

class VAE(nn.Module):
  
    def __init__(self):
        super(VAE, self).__init__()
        self.encoder = Encoder()
        self.decoder = Decoder()
        
        self.encoder.apply(dcgan_init)
        self.decoder.apply(dcgan_init)
        
        self.criterion = nn.MSELoss(reduction='sum')
        self.batch_size = 0
        
    def reparametrize(self, mean, logvar):
        std = torch.exp(0.5*logvar) 
        eta = torch.randn_like(mean)  
        return eta.mul(std).add_(mean)
        
    def forward(self, x):
        self.batch_size = x.size()[0]
        mean, logvar = self.encoder(x)
        z = self.reparametrize(mean, logvar)
        z_size = z.size()
        z = z.view(z_size[0], z_size[1], 1, 1)
        reconstrunction_pixel_means = self.decoder(z)
        return reconstrunction_pixel_means, mean, logvar
      
      
    def loss(self, reconstrunction_pixel_means, x, mean, logvar):
        recon_loss = self.criterion(reconstrunction_pixel_means, x)
        kl_loss = -0.5 * torch.sum(1 + logvar - mean**2 - torch.exp(logvar))
        return recon_loss , kl_loss


